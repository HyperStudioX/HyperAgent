# HyperAgent API Configuration

# ============================================================
# Environment
# ============================================================
DEBUG=false
ENVIRONMENT=development

# ============================================================
# LLM Providers (at least one required)
# ============================================================
# Anthropic API key (for Claude models)
ANTHROPIC_API_KEY=

# OpenAI API key (for GPT models, DALL-E, Whisper, TTS)
OPENAI_API_KEY=

# Google Gemini API key
GEMINI_API_KEY=

# Default Provider (anthropic, openai, gemini, or any custom provider name)
DEFAULT_PROVIDER=anthropic

# Custom OpenAI-Compatible Providers (JSON array)
# Each entry: {"name": "...", "api_key": "...", "base_url": "...", "default_model": "...", "display_name": "...",
#   "tier_models": {"max": "...", "pro": "...", "flash": "..."},
#   "image_model": "...", "vision_model": "..."}
# Note: "default_model" is optional if "tier_models" is provided (will use pro > flash > max as fallback)
# "image_model" and "vision_model" are optional; used when this provider is set as IMAGE_MODEL_PROVIDER or VISION_MODEL_PROVIDER
# Example:
# CUSTOM_PROVIDERS=[{"name":"deepseek","api_key":"sk-...","base_url":"https://api.deepseek.com","default_model":"deepseek-chat","display_name":"DeepSeek"},{"name":"groq","api_key":"gsk_...","base_url":"https://api.groq.com/openai/v1","default_model":"llama-3.3-70b-versatile","display_name":"Groq"}]
CUSTOM_PROVIDERS=

# Per-Tier Provider Override
# Set a different provider for specific tiers. Leave blank to use DEFAULT_PROVIDER.
# Example: Use Anthropic Opus for complex tasks, Gemini Flash for quick tasks.
MAX_MODEL_PROVIDER=
PRO_MODEL_PROVIDER=
FLASH_MODEL_PROVIDER=

# Vision (Image Understanding) Provider Override
# Controls which provider is used for analyzing/understanding images.
# Leave blank to use DEFAULT_PROVIDER. Supported: gemini, openai
VISION_MODEL_PROVIDER=

# Image Generation Provider Override
# Controls which provider is used for image generation.
# Leave blank to use IMAGE_GEN_DEFAULT_PROVIDER.
IMAGE_MODEL_PROVIDER=

# ============================================================
# GCP / Vertex AI (use Vertex AI instead of Google AI Studio for Gemini)
# ============================================================
GEMINI_USE_VERTEX_AI=false
GCP_PROJECT_ID=
GCP_LOCATION=us-central1

# ============================================================
# Model Tier Configuration
# ============================================================
# The tier system automatically selects models based on task complexity:
# - MAX tier: Research, writing, complex reasoning tasks
# - PRO tier: Chat, code assistance, data analysis (also used as the default model)
# - FLASH tier: Routing decisions, quick summaries, simple tasks
#
# All tiers use DEFAULT_PROVIDER above. Configure per-provider models below.
# Users can override the auto-selection via the UI or API.
# Leave blank to use defaults defined in config.py

# MAX Tier Models (Complex tasks requiring deep reasoning)
TIER_MAX_ANTHROPIC=claude-opus-4-20250514
TIER_MAX_OPENAI=gpt-4o
TIER_MAX_GEMINI=gemini-2.5-pro

# PRO Tier Models (Balanced general-purpose tasks)
TIER_PRO_ANTHROPIC=claude-sonnet-4-20250514
TIER_PRO_OPENAI=gpt-4o-mini
TIER_PRO_GEMINI=gemini-2.5-flash

# FLASH Tier Models (Quick, cost-efficient tasks)
TIER_FLASH_ANTHROPIC=claude-3-5-haiku-20241022
TIER_FLASH_OPENAI=gpt-4o-mini
TIER_FLASH_GEMINI=gemini-2.0-flash

# ============================================================
# Multimodal Services
# ============================================================

# --- Image Understanding (Vision) - per-provider models ---
VISION_MODEL_GEMINI=gemini-2.5-flash
VISION_MODEL_OPENAI=gpt-4o

# --- Image Generation - per-provider models ---
IMAGE_GEN_MODEL_GEMINI=gemini-3-pro-image-preview
IMAGE_GEN_MODEL_OPENAI=dall-e-3
IMAGE_GEN_SAFETY_FILTER=block_some  # block_none, block_some, block_most
IMAGE_GEN_OPENAI_QUALITY=standard  # standard or hd

# ============================================================
# Database & Cache
# ============================================================
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/hyperagent
REDIS_URL=redis://localhost:6379

# ============================================================
# File Storage
# ============================================================
# Backend: "local" for development (stores files in ./uploads), "r2" for production (Cloudflare R2)
STORAGE_BACKEND=local
LOCAL_STORAGE_PATH=./uploads

# Cloudflare R2 Storage (only needed if STORAGE_BACKEND=r2)
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET_NAME=hyperagent
R2_ENDPOINT_URL=

# ============================================================
# LangGraph Configuration
# ============================================================
# Maximum recursion depth for graph execution (default: 50)
LANGGRAPH_RECURSION_LIMIT=50

# ============================================================
# ReAct Loop Configuration
# ============================================================
# Maximum number of tool-calling iterations (default: 5)
# Controls how many times the agent can call tools in a single turn
REACT_MAX_ITERATIONS=5

# ============================================================
# Sandbox Provider
# ============================================================
# Which sandbox backend to use: "e2b" (cloud) or "boxlite" (local Docker)
SANDBOX_PROVIDER=e2b

# ============================================================
# E2B Cloud Sandbox (used when SANDBOX_PROVIDER=e2b)
# ============================================================
# E2B Sandbox API key (required for code execution agent)
E2B_API_KEY=

# Optional: Custom E2B template ID with pre-installed packages
E2B_TEMPLATE_ID=

# ============================================================
# BoxLite Local Sandbox (used when SANDBOX_PROVIDER=boxlite)
# ============================================================
# Requires: pip install 'hyperagent-api[local-sandbox]'
# Docker images for each sandbox type
BOXLITE_CODE_IMAGE=python:3.12-slim
BOXLITE_DESKTOP_IMAGE=boxlite/desktop:latest
BOXLITE_APP_IMAGE=node:20-slim

# Container resource limits
BOXLITE_CPUS=2
BOXLITE_MEMORY_MIB=1024
BOXLITE_DISK_SIZE_GB=4

# Default browser in desktop containers (chromium-browser for webtop image)
BOXLITE_DESKTOP_DEFAULT_BROWSER=chromium-browser

# Timeouts (seconds)
BOXLITE_CODE_TIMEOUT=300
BOXLITE_DESKTOP_TIMEOUT=900

# Auto-remove containers on cleanup
BOXLITE_AUTO_REMOVE=true

# Starting host port for app sandbox port forwarding
BOXLITE_APP_HOST_PORT_START=10000

# ============================================================
# Search & Tools
# ============================================================
# Tavily API key (required for web search functionality)
TAVILY_API_KEY=

# ============================================================
# Rate Limiting
# ============================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_RPM=30

# ============================================================
# Logging
# ============================================================
LOG_LEVEL=INFO
LOG_FORMAT=console

# ============================================================
# CORS Configuration
# ============================================================
# Comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:5000,http://localhost:3000

# ============================================================
# Authentication
# ============================================================
NEXTAUTH_SECRET=
AUTH_ENABLED=true
